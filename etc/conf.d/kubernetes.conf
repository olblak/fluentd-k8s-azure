<source>
   type tail 
   tag kubernetes.*
   path /var/log/containers/*.log
   pos_file Fluentd-docker.pos
   format json
   read_from_head true
   keep_time_key true
   time_key time
   time_format %Y-%m-%dT%H:%M:%S.%NZ
   log_level KUBERNETES_LOG_LEVEL
</source>

# Add kubernetes metadata informations
<filter kubernetes.var.log.containers.*.log>
   type kubernetes_metadata
   ca_file /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
   bearer_token_file /var/run/secrets/kubernetes.io/serviceaccount/token
   ## By default kubernetes doesn't add CN=10.0.0.1 to his CA
   ## so ssl verification will always be failing
   verify_ssl false
</filter>

# Add record labels to simply next step.
# So we reduce scope to search for specific pattern
<filter kubernetes.**>
  type record_transformer
  enable_ruby
  <record>
    labels "${kubernetes[\"labels\"]}"
	auto_typecast true
  </record>
</filter>

# Search pattern in labels strings
# Return tag stream if no logtype founded
<match kubernetes.**>
  @type rewrite_tag_filter
  rewriterule1 labels (\"logtype\"=>\"archive\")    archive.${tag}
  rewriterule2 labels !\"logtype\":  stream.${tag}
</match>

# Handle logs to stream
<match stream.** >
    @type copy
    <store stream.**>
        @type forest
        subtype file 
        <template>
            path /fluentd/log/stream/${tag_parts[5]}.*.log
            compress gzip
            format json
        </template>
    </store>
    <store>
    	@type azure-loganalytics
    	customer_id CUSTOMER_ID   # Customer ID aka WorkspaceID String
    	shared_key KEY_STRING     # The primary or the secondary Connected Sources client authentication key
    	log_type Kubernetes # ! Only alpha character, no num!
        log_level KUBERNETES_LOG_LEVEL
    </store>
</match>

# Handle logs to archive
<match archive.**>
    @type copy
    # Send logs locally
    <store>
        @type forest
        subtype file
        <template>
		    path /fluentd/log/archive/${tag_parts[5]}.*.log
            compress gzip
            format json
        </template>
    </store>
    # Send logs to loganalytics
    <store>
    	@type azure-loganalytics
    	customer_id CUSTOMER_ID   # Customer ID aka WorkspaceID String
    	shared_key KEY_STRING     # The primary or the secondary Connected Sources client authentication key
    	log_type Kubernetes # ! Only alpha character, no num!
        log_level KUBERNETES_LOG_LEVEL
    </store>
    # Send logs to containers
    # This plugin had dependency on old azure SDK 0.6.4
    # https://github.com/htgc/fluent-plugin-azurestorage/issues/12 
    # It should be fixed before getting used
    #<store>
    #    type azurestorage
    #    azure_storage_account    AZURE_ARCHIVE_STORAGE_ACCOUNT
    #    azure_storage_access_key AZURE_ARCHIVE_STORAGE_ACCESS_KEY
    #    azure_container          AZURE_ARCHIVE_CONTAINER
    #    azure_storage_type       blob
    #    store_as                 gzip 
    #    auto_create_container    true
    #    path                     logs/kubernetes/
    #    azure_object_key_format  %{path}%{time_slice}_%{index}.%{file_extension}
    #    buffer_path              /var/log/fluent/azurestorage
    #    time_slice_format        %Y%m%d-%H
    #    time_slice_wait          10m
    #    utc
    #</store>
</match>

<match **>
    @type forest
    subtype file 
    <template>
        path /fluentd/log/uncatched/
        compress gzip
        format json
    </template>
</match>
